{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 6: Ontologies and Document Classification \n",
    "\n",
    "\n",
    "Ontologies are sets of words that are used to help discern what is being talked about in digitized, text based information. \n",
    "\n",
    "You learned a little bit about how this works in modules 5 and 6, because you dissected the words that are common in a particular set of books. \n",
    "\n",
    "What are ontologies used for in practice, though? How would a data scientist deploy them?  \n",
    "\n",
    "Maybe the easiest way to show you is with a few examples from my research. \n",
    "1. Processing Twitter Data to Identify Events: [Football and Baseball Ontologies](./resources/baseball.pdf)\n",
    "2. Processing online health support forums to identify the type of support being provided: Emotional, community or informational: [WebMD Health Support Forum Ontologies](./resources/onlinehealth.pdf)\n",
    "3. Noting the emergence of terms in an adult kickball league's online discussion forum: [Finding Ontologies Where None Exist Yet - Topic Modeling](./resources/kickball.pdf)\n",
    "\n",
    "In each case you will notice that we picked a specific ontology with which to make sense of what was happening.  In the case of Twitter, we used player names and sport specific words like \"out\" for baseball and \"touchdown\" for football to identify new events on the field through the Twitter feed. \n",
    "\n",
    "In online health support forums, we used ontologies of emotional, informational and community support words to identify specific types of support.  You will see, if you look through the paper casually (skimming is OK!) that some health conditions elicit different levels of different types of support, and exhibit different membership stability (unrelated to ontology, but still pretty cool!). \n",
    "\n",
    "Think about an ontology - sports, a hobby, health related - that you might want to use to classify a set of text. Its likely to come up again. :) \n",
    "\n",
    "Here are links to the labs and practices for this modules.  \n",
    "\n",
    "**Labs**\n",
    "1. [Lab: Text Analysis with Python](./labs/Lab_06.01_TextAnalysis_Python.ipynb)\n",
    "2. [Lab: Text Classification](./labs/Lab_06.03_Text_Classification.ipynb)\n",
    "3. [Lab: Ngrams and Text Clustering](./labs/Lab_06.04_Ngrams_Clustering.ipynb)\n",
    "\n",
    "**Practices** \n",
    "\n",
    "1. [Practice: Classification](./practices/Practice_06.01_Classification.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## If the text below doesn't work, install this library by uncommenting\n",
    "## the line below:\n",
    "\n",
    "# install.packages(\"tidytext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### An Opening Example\n",
    "So, lets take this example:\n",
    "\n",
    "Let's count the number of words in Jane Austen Novels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(janeaustenr)\n",
    "library(tidytext)\n",
    "\n",
    "book_words <- austen_books() %>%\n",
    "  unnest_tokens(word, text) %>%\n",
    "  count(book, word, sort = TRUE) %>%\n",
    "  ungroup()\n",
    "\n",
    "total_words <- book_words %>% \n",
    "  group_by(book) %>% \n",
    "  summarize(total = sum(n))\n",
    "\n",
    "book_words <- left_join(book_words, total_words)\n",
    "\n",
    "book_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one row in this book_words data frame for each word-book combination; n is the number of times that word is used in that book and total is the total words in that book. The usual suspects are here with the highest n, “the”, “and”, “to”, and so forth. In Figure 3.1, let’s look at the distribution of n/total for each novel, the number of times a word appears in a novel divided by the total number of terms (words) in that novel. This is exactly what term frequency is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "ggplot(book_words, aes(n/total, fill = book)) +\n",
    "  geom_histogram(show.legend = FALSE) +\n",
    "  xlim(NA, 0.0009) +\n",
    "  facet_wrap(~book, ncol = 2, scales = \"free_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of tf-idf is to find the important words for the content of each document by decreasing the weight for commonly used words and increasing the weight for words that are not used very much in a collection or corpus of documents, in this case, the group of Jane Austen’s novels as a whole. Calculating tf-idf attempts to find the words that are important (i.e., common) in a text, but not too common. Let’s do that now.\n",
    "\n",
    "The bind_tf_idf function in the tidytext package takes a tidy text dataset as input with one row per token (term), per document. One column (word here) contains the terms/tokens, one column contains the documents (book in this case), and the last necessary column contains the counts, how many times each document contains each term (n in this example). We calculated a total for each book for our explorations in previous sections, but it is not necessary for the bind_tf_idf function; the table only needs to contain all the words in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_words <- book_words %>%\n",
    "  bind_tf_idf(word, book, n)\n",
    "book_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that idf and thus tf-idf are zero for these extremely common words. These are all words that appear in all six of Jane Austen’s novels, so the idf term (which will then be the natural log of 1) is zero. The inverse document frequency (and thus tf-idf) is very low (near zero) for words that occur in many of the documents in a collection; this is how this approach decreases the weight for common words. The inverse document frequency will be a higher number for words that occur in fewer of the documents in the collection.\n",
    "\n",
    "Let’s look at terms with high tf-idf in Jane Austen’s works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_words %>%\n",
    "  select(-total) %>%\n",
    "  arrange(desc(tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at a visualization for these high tf-idf words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_austen <- book_words %>%\n",
    "  arrange(desc(tf_idf)) %>%\n",
    "  mutate(word = factor(word, levels = rev(unique(word))))\n",
    "\n",
    "plot_austen %>% \n",
    "  top_n(20) %>%\n",
    "  ggplot(aes(word, tf_idf, fill = book)) +\n",
    "  geom_col() +\n",
    "  labs(x = NULL, y = \"tf-idf\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, if you're really into Jane Austen, you'll probably want to see the novels individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_austen %>% \n",
    "  group_by(book) %>% \n",
    "  top_n(15) %>% \n",
    "  ungroup %>%\n",
    "  ggplot(aes(word, tf_idf, fill = book)) +\n",
    "  geom_col(show.legend = FALSE) +\n",
    "  labs(x = NULL, y = \"tf-idf\") +\n",
    "  facet_wrap(~book, ncol = 2, scales = \"free\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets\n",
    "\n",
    "For this module, our data sets are files to process.\n",
    "\n",
    "Found in the root directory datasets folder:\n",
    "Path: `../../../../datasets/DSA-8630/newsgroups/`\n",
    "\n",
    " Dataset Name                | Files\n",
    "-----------------------------|------------\n",
    " newsgroups                  | `newsgroups/` \n",
    " tweets                      | `DSA-8630/tweets.csv` \n",
    " \n",
    " \n",
    " Found in the course datasets folder\n",
    " Path: `../../../datasets/`\n",
    " \n",
    " Dataset Name                | Files\n",
    "-----------------------------|------------\n",
    " movie_reviews               | `movie_reviews` \n",
    "\n",
    "\n",
    " Symlink to the directory is found in the exercise folder\n",
    "\n",
    " Dataset Name                | Files\n",
    "-----------------------------|------------\n",
    " book                        | `book` \n",
    "\n",
    "   \n",
    "## Suggested Schedule\n",
    "- Note: There is no topic discussion this week. \n",
    "- Please participate in Mutual Aid on Slack. Post questions you have, and post things you discovered or learned. Offer suggestions or answers for your classmates' questions.\n",
    "\n",
    "### Monday - Tuesday\n",
    "    \n",
    "  - **Lab Notebooks**: \n",
    "    1. Lab: Text Analysis with Python\n",
    "    2. Lab: Text Analysis with R\n",
    "    3. Lab: Text Classification\n",
    "    4. Lab: Ngrams and Text Clustering\n",
    "     \n",
    "### Wednesday\n",
    "  - **Practice Notebooks**\n",
    "      1. Practice: Classification\n",
    "      \n",
    "\n",
    "### Thursday\n",
    "  - Practice answers to be released\n",
    "  - **Exercises **: \n",
    "  \n",
    "  <span style=\"color:red\">Exercise to be deployed later in the week.</span>\n",
    "      1. Exercise 06.01 \n",
    "\n",
    "### Next Wednesday\n",
    "  - **Exercise Due**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
