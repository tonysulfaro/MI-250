{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Practice: Sentiment Analysis Classification\n",
    "\n",
    "In this notebook we will try to solve a classification problem where the goal is to classify movie reviews based on sentiment, negative or positive. This notebook presents the problem in its simplest terms unlike the sophisticated sentiment analysis which is done based on the presence or absence of specific words. We will use scikit learn data loading functionality to build training and testing data.\n",
    "\n",
    "The notebook is partially complete. Look for \"Your code here\" to complete the partial code.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 1: ** Load the data from '../../../datasets/movie_reviews' into the mvr variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "mvr = nltk.corpus.movie_reviews\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "data_dir = '../../../datasets/movie_reviews'\n",
    "mvr = <Your code here to load the movie reviews data in above path>\n",
    "print('Number of Reviews: {0}' <Your code here to print the number of reviews>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2: ** Split the data in mvr.data into train(mvr_train) and test(mvr_test) datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mvr_train, mvr_test, y_train, y_test = train_test_split(\n",
    "    <Your code here to select reviews data>, \n",
    "    <Your code here to select movie reviews target data>, \n",
    "    test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Now that the training and testing data have been loaded into the notebook, we can build a simple pipeline by using a `CountVectorizer` and `MultinomialNB` to build a document-term matrix and to perform a Naive Bayes classification.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 3: ** Build a pipeline by using a `CountVectorizer` and `MultinomialNB` to build a document-term matrix and to perform a Naive Bayes classification. Print the metrics of classification result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build simple pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "pipeline = Pipeline(<Your code here to build pipeline for CountVectorizer and MultinomialNB)\n",
    "\n",
    "# Build DTM and classify data\n",
    "pipeline.fit(mvr_train, y_train)\n",
    "\n",
    "# Predict the reviews on mvr_test data\n",
    "y_pred = <Your code here to make predictions on test data>\n",
    "\n",
    "# Print the prediction results\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = mvr.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 4: ** Use stop words in above `CountVectorizer`. Build the document-term matrix and perform a Naive Bayes classification again. Print the metrics of the new classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline.<Your code to use stop words with countVectorizer>\n",
    "\n",
    "# Build DTM and classify data\n",
    "pipeline.fit(mvr_train, y_train)\n",
    "y_pred = pipeline.predict(mvr_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = mvr.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Activity 5: ** Change the vectorizer to TF-IDF. Perform a Naive Bayes classification again. Print the metrics of new classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pipeline = Pipeline(<Your code here to build pipeline for TF-IDF and MultinomialNB)\n",
    "\n",
    "pipeline.set_params(tf__stop_words = 'english')\n",
    "\n",
    "\n",
    "# Build DTM and classify data\n",
    "clf.fit(mvr_train, y_train)\n",
    "y_pred = clf.predict(mvr_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = mvr.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 6: ** Change the TF-IDF parameters, such as `max_features` and `lowercase`. perform a Naive Bayes classification again. Print the metrics of the new classification results.\n",
    "\n",
    "Note: Find the documentation for [TfidfVectorizer here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to find the right values for max_features and lowercase. Play around with the parameter to see how results are changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tools = [('tf', TfidfVectorizer()), ('nb', MultinomialNB())]\n",
    "clf = Pipeline(tools)\n",
    "clf.<Your code to use max_features and lowercase with TfidfVectorizer>\n",
    "\n",
    "\n",
    "# Build DTM and classify data\n",
    "clf.fit(mvr_train, y_train)\n",
    "y_pred = clf.predict(mvr_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = mvr.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 7: ** Change the classifier to the logistic regression algorithm. Print the results metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "tools = <Your code here to build pipeline for TF-IDF and LogisticRegression>\n",
    "clf = Pipeline(tools)\n",
    "clf.set_params(tf__stop_words = 'english')\n",
    "\n",
    "\n",
    "# Build DTM and classify data\n",
    "clf.fit(mvr_train, y_train)\n",
    "y_pred = clf.predict(mvr_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = mvr.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
