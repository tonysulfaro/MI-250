{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1: Computational Linguistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational linguistics applies many of the concepts you learned in the previous module to specific challenges in the Real World.  For example, when examining a corpora of text, like a person's tweets, what can we learn about how and what is expressed in that corpora by examining words and combinations of words? \n",
    "\n",
    "Is there a story that emerges?\n",
    "\n",
    "Fortunately, we live in an era where famous people frequently use Twitter; and Twitter is good at producing a large number of finite (small) sets of words for us to examine. \n",
    "\n",
    "Lets take a look at some tweets from Donald Trump over the past year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lets import some libraries form mathplotlib ... its helpful for plotting. \n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All the packages we are using in this project\n",
    "from __future__ import division\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tweets from Donald Trump are stored in file 'realDonaldTrump_tweets.txt' in the current directory\n",
    "\n",
    "## Text Analysis\n",
    "- Text collocations to find common words that go together\n",
    "- Regular expression to parse out hashtags and high frequent user account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'realDonaldTrump_tweets.txt'\n",
    "\n",
    "## realDonaldTrump_tweets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we uses Regular expression to strip away symbols and web links in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as f:\n",
    "    raw = re.sub(r'[^\\w]|https.*\\b', ' ', f.read())\n",
    "    tokens = word_tokenize(raw)\n",
    "    freqDist = nltk.FreqDist(tokens)\n",
    "freqDist.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "def plot_ngram(tokens, num):\n",
    "    ngram = ngrams(tokens, num)\n",
    "    ngram_dist = nltk.FreqDist(ngram)\n",
    "    ngram_dist.plot(25)\n",
    "\n",
    "plot_ngram(tokens, 2) ##bigram frequency distribution\n",
    "plot_ngram(tokens, 3) ##trigram frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique trump tweet vocab: %i (including capitalized letters)\" % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that \"Crooked Hillary\", \"FAKE NEWS\" are all the slogans that Trump frequently uses in his campaign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    hasher =  f.read()\n",
    "    tokens = word_tokenize(raw)\n",
    "    freqDist = nltk.FreqDist(tokens)\n",
    "\n",
    "hashtags = re.findall(r\"#(\\w+)\", hasher)\n",
    "freqDist_hashtags = nltk.FreqDist(hashtags)\n",
    "hashtags = []\n",
    "for freq in freqDist_hashtags.keys():\n",
    "    hashtags.append((freq, freqDist_hashtags[freq]))\n",
    "sorted_hashtags = sorted(hashtags, key=itemgetter(1), reverse=True) #Sort by frequency\n",
    "\n",
    "#find the top 50 most used hashtags by Donald Trump\n",
    "print([text[0] for text in sorted_hashtags[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDist_hashtags.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension Check:\n",
    "\n",
    "What do these hashtags tell you about the nature of Trumps Tweets? What are the common topics? Are they positive or negative do you think? Some of both? Explain based on the data above.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who is addressed the most in Trump's tweets (via mentions)\n",
    "\n",
    "Note that, below, the code is looking for the \"@\" symbol, which is how people are mentioned on Twitter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_users = re.findall(r\"@(\\w+)\", hasher)\n",
    "freq_users = nltk.FreqDist(tag_users)\n",
    "tag_users = []\n",
    "for freq in freq_users.keys():\n",
    "    tag_users.append((freq, freq_users[freq]))\n",
    "tag_users = sorted(tag_users, key=itemgetter(1), reverse=True) #Sort by frequency\n",
    "\n",
    "print([text[0] for text in tag_users[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_users.plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprehension Check:\n",
    "\n",
    "What types of accounts are most frequently mentioned in Trump's tweets? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Comprehension Check :\n",
    "\n",
    "\n",
    "Based on your analysis of the data from Trump's tweets, what can you say about how Twitter is used? \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "Does this validate or invalidate how you thought about Trump's tweets previously? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
